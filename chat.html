<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dharma Chat - Local AI</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        :root {
            --bg: #1a1a1a;
            --surface: #2a2a2a;
            --text: #e0e0e0;
            --text-muted: #888;
            --accent: #c9a962;
            --user-bg: #3a3a3a;
            --ai-bg: #2d2d2d;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: var(--bg);
            color: var(--text);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        header {
            padding: 1rem;
            text-align: center;
            border-bottom: 1px solid #333;
        }

        h1 {
            font-size: 1.3rem;
            color: var(--accent);
            margin-bottom: 0.25rem;
        }

        .subtitle {
            font-size: 0.8rem;
            color: var(--text-muted);
        }

        #status {
            padding: 0.75rem;
            text-align: center;
            font-size: 0.85rem;
            color: var(--text-muted);
            background: var(--surface);
        }

        #status.loading { color: var(--accent); }
        #status.ready { color: #6b8e6b; }
        #status.error { color: #c97a7a; }

        #chat {
            flex: 1;
            overflow-y: auto;
            padding: 1rem;
            display: flex;
            flex-direction: column;
            gap: 1rem;
        }

        .message {
            max-width: 85%;
            padding: 0.75rem 1rem;
            border-radius: 1rem;
            line-height: 1.5;
            white-space: pre-wrap;
        }

        .message.user {
            align-self: flex-end;
            background: var(--user-bg);
            border-bottom-right-radius: 0.25rem;
        }

        .message.ai {
            align-self: flex-start;
            background: var(--ai-bg);
            border-bottom-left-radius: 0.25rem;
            border-left: 2px solid var(--accent);
        }

        .message.system {
            align-self: center;
            background: transparent;
            color: var(--text-muted);
            font-size: 0.85rem;
            font-style: italic;
            text-align: center;
        }

        #input-area {
            padding: 1rem;
            border-top: 1px solid #333;
            display: flex;
            gap: 0.5rem;
        }

        #input {
            flex: 1;
            padding: 0.75rem 1rem;
            border: 1px solid #444;
            border-radius: 1.5rem;
            background: var(--surface);
            color: var(--text);
            font-size: 1rem;
            outline: none;
        }

        #input:focus { border-color: var(--accent); }
        #input::placeholder { color: var(--text-muted); }

        #send {
            padding: 0.75rem 1.25rem;
            background: var(--accent);
            color: #1a1a1a;
            border: none;
            border-radius: 1.5rem;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: opacity 0.2s;
        }

        #send:disabled { opacity: 0.5; cursor: not-allowed; }
        #send:hover:not(:disabled) { opacity: 0.9; }

        .typing span {
            display: inline-block;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 0.3; }
            50% { opacity: 1; }
        }

        a { color: var(--accent); }

        #error-details {
            font-size: 0.75rem;
            margin-top: 0.5rem;
            color: #c97a7a;
        }
    </style>
</head>
<body>
    <header>
        <h1>Dharma Chat</h1>
        <p class="subtitle">Local AI running in your browser via WebGPU</p>
    </header>

    <div id="status" class="loading">
        Checking WebGPU support...
    </div>

    <div id="chat">
        <div class="message system">
            This AI runs entirely in your browser. First load downloads the model (~80MB). All conversations stay private on your device.
        </div>
    </div>

    <div id="input-area">
        <input type="text" id="input" placeholder="Ask about Buddhism, meditation, the dharma..." disabled>
        <button id="send" disabled>Send</button>
    </div>

    <script type="module">
        const chat = document.getElementById('chat');
        const input = document.getElementById('input');
        const sendBtn = document.getElementById('send');
        const status = document.getElementById('status');

        let generator = null;

        const BUDDHISM_CONTEXT = `You are a wise and compassionate Buddhist teacher. Answer questions about Buddhism, meditation, the Four Noble Truths, the Eightfold Path, mindfulness, and dharma teachings. Keep responses clear, warm, and concise.

User: `;

        function log(msg) {
            console.log('[DharmaChat]', msg);
        }

        function addMessage(content, type) {
            const div = document.createElement('div');
            div.className = `message ${type}`;
            div.textContent = content;
            chat.appendChild(div);
            chat.scrollTop = chat.scrollHeight;
            return div;
        }

        function setStatus(text, type) {
            status.textContent = text;
            status.className = type || '';
        }

        async function initModel() {
            // Check WebGPU
            if (!navigator.gpu) {
                setStatus('WebGPU not available. Try Chrome 113+ or Edge.', 'error');
                return false;
            }

            try {
                const adapter = await navigator.gpu.requestAdapter();
                if (!adapter) {
                    setStatus('No WebGPU adapter found. Your GPU may not be supported.', 'error');
                    return false;
                }
                log('WebGPU adapter found');
            } catch (e) {
                setStatus('WebGPU error: ' + e.message, 'error');
                return false;
            }

            setStatus('Loading Transformers.js library...', 'loading');

            try {
                // Dynamic import of transformers.js
                const { pipeline, env } = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2');

                // Use WebGPU backend if available
                env.backends.onnx.wasm.numThreads = 1;

                setStatus('Downloading AI model (first time only, ~150MB)...', 'loading');
                log('Starting model download...');

                generator = await pipeline('text-generation', 'Xenova/distilgpt2', {
                    progress_callback: (progress) => {
                        if (progress.status === 'downloading') {
                            const pct = Math.round((progress.loaded / progress.total) * 100) || 0;
                            setStatus(`Downloading: ${progress.file} (${pct}%)`, 'loading');
                        } else if (progress.status === 'loading') {
                            setStatus('Loading model into memory...', 'loading');
                        }
                    }
                });

                log('Model loaded successfully');
                setStatus('Ready - AI running locally', 'ready');
                input.disabled = false;
                sendBtn.disabled = false;
                input.focus();
                return true;

            } catch (err) {
                log('Error: ' + err.message);
                console.error(err);
                setStatus('Failed to load model. See console for details.', 'error');

                const details = document.createElement('div');
                details.id = 'error-details';
                details.textContent = err.message;
                status.appendChild(details);
                return false;
            }
        }

        async function sendMessage() {
            const text = input.value.trim();
            if (!text || !generator) return;

            input.value = '';
            sendBtn.disabled = true;
            input.disabled = true;

            addMessage(text, 'user');

            const thinkingMsg = addMessage('Contemplating...', 'ai');
            thinkingMsg.innerHTML = '<span class="typing"><span>Thinking</span></span>';

            try {
                log('Generating response...');
                const prompt = BUDDHISM_CONTEXT + text + "\n\nTeacher:";

                const result = await generator(prompt, {
                    max_new_tokens: 100,
                    temperature: 0.7,
                    do_sample: true,
                    top_p: 0.9,
                });

                log('Response generated');

                let response = result[0].generated_text;
                // Extract just the teacher's response
                response = response.split("Teacher:").pop().trim();
                // Cut off at any "User:" to avoid continuation
                if (response.includes("User:")) {
                    response = response.split("User:")[0].trim();
                }

                thinkingMsg.textContent = response || "I am here to help you on the path. Please ask your question again.";

            } catch (err) {
                log('Generation error: ' + err.message);
                console.error(err);
                thinkingMsg.textContent = 'Error generating response. Please try again.';
            }

            sendBtn.disabled = false;
            input.disabled = false;
            input.focus();
        }

        sendBtn.addEventListener('click', sendMessage);
        input.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                sendMessage();
            }
        });

        // Start loading
        initModel();
    </script>
</body>
</html>
